pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment", NA
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment", "NA")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
print(sort(unique(filtered$survey_city)))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
print(sort(unique(filtered$survey_city)))
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
unique(filtered$survey_city)
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
sort(unique(filtered$survey_city))
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
print(sort(unique(filtered$survey_city)))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
print(sort(unique(filtered$survey_city)))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
sort(unique(filtered$survey_state))
print(sort(unique(filtered$survey_state)))
unique(filtered$survey_state))
unique(filtered$survey_state)
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
sort(unique(filtered$survey_city))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
sort(unique(filtered$survey_city))
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
sort(unique(filtered$survey_city))
filtered$survey_company <- tolower(filtered$survey_company) # to lower case
sort(unique(filtered$survey_company))
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
sort(unique(filtered$survey_city))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
sort(unique(filtered$survey_city))
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
sort(unique(filtered$survey_city))
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.2
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
install.packages("stringdist")
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.2
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
install.packages("stringdist")
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.2
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
clustered_data
install.packages("stringdist")
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.5
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
sort(unique(filtered$survey_city))
install.packages("stringdist")
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.5
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
sort(unique(filtered$survey_city))
sort(unique(filtered$survey_company))
clustered_data
data <- filtered
# Create an empty vector to store the matched names
matched_names <- character(0)
# Loop through the company names and find matches for each
for (search_term in data$survey_company) {
fuzzy_matches <- stringdistmatrix(search_term, data$survey_company, method = "jw")
# Adjust the threshold as needed
threshold <- 0.5  # You can adjust this threshold
# Find matches with a similarity threshold
potential_matches <- which(fuzzy_matches <= threshold, arr.ind = TRUE)
# Get the matched company names using row index
matched_names <- c(matched_names, data$survey_company[potential_matches[, "row"]])
}
data <- filtered$survey_company
# Create an empty vector to store the matched names
matched_names <- character(0)
# Loop through the company names and find matches for each
for (search_term in data$survey_company) {
fuzzy_matches <- stringdistmatrix(search_term, data$survey_company, method = "jw")
# Adjust the threshold as needed
threshold <- 0.5  # You can adjust this threshold
# Find matches with a similarity threshold
potential_matches <- which(fuzzy_matches <= threshold, arr.ind = TRUE)
# Get the matched company names using row index
matched_names <- c(matched_names, data$survey_company[potential_matches[, "row"]])
}
data <- filtered
# Create an empty vector to store the matched names
matched_names <- character(0)
# Loop through the company names and find matches for each
for (search_term in data$survey_company) {
fuzzy_matches <- stringdistmatrix(search_term, data$survey_company, method = "jw")
# Adjust the threshold as needed
threshold <- 0.5  # You can adjust this threshold
# Find matches with a similarity threshold
potential_matches <- which(fuzzy_matches <= threshold, arr.ind = TRUE)
# Get the matched company names using row index
matched_names <- c(matched_names, data$survey_company[potential_matches[, "row"]])
}
# Add the matched names to the original data frame
data$matched_names <- matched_names
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
R.version
filtered$survey_company <- tolower(filtered$survey_company) # to lower case
filtered$survey_company[filtered$survey_company == "84.51º"] <- "84.51"
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
sort(unique(filtered$survey_city))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
sort(unique(filtered$survey_city))
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
sort(unique(filtered$survey_city))
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.5
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
sort(unique(filtered$survey_company))
filtered$survey_company <- tolower(filtered$survey_company) # to lower case
filtered$survey_company[filtered$survey_company == "84.51º"] <- "84.51"
filtered$survey_company[filtered$survey_company == "abbott nutrition"] <- "abbott"
filtered$survey_company[filtered$survey_company == "abercrombie"] <- "abercrombie & fitch"
filtered$survey_company[filtered$survey_company == "aldi us" | filtered$survey_company == "aldi usa"] <- "aldi"
filtered$survey_company[filtered$survey_company == "american eagle outfitters" | filtered$survey_company == "american eagle outfitters, Inc."] <- "american eagle"
filtered$survey_company[filtered$survey_company == "amazon web services"] <- "amazon"
filtered$survey_company[filtered$survey_company == "american electric power (aep)"] <- "american electric power"
filtered$survey_company[filtered$survey_company == "ameriprise financial - redstone wealth advisors"] <- "ameriprise financial services"
filtered$survey_company[filtered$survey_company == "andersen"] <- "andersen tax"
filtered$survey_company[filtered$survey_company == "ankura"] <- "ankura consulting"
filtered$survey_company[filtered$survey_company == "ayco, a goldman sachs company"] <- "ayco"
filtered$survey_company[filtered$survey_company == "barclays"] <- "barclays investment bank"
filtered$survey_company[filtered$survey_company == "bath & body works"] <- "bath and body works"
filtered$survey_company[filtered$survey_company == "baxter"] <- "baxter international"
filtered$survey_company[filtered$survey_company == "bdo usa" | filtered$survey_company == "bdo usa llp"] <- "bdo"
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
plot_missing(data_filtered2)
filtered <- subset(data_filtered2, !is.na(survey_plans))
plot_missing(filtered)
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
sort(unique(filtered$survey_city))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
sort(unique(filtered$survey_city))
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
sort(unique(filtered$survey_city))
create_report(filtered)
max(filtered$survey_salary)
summary(filtered$survey_salary)
summary(data)
str(data)
