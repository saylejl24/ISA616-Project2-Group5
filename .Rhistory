data_filtered2 <- data_filtered[, c(2,3,22,23,24,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
View(data_filtered2)
data_filtered2 <- na.omit(data_filtered2, cols='survey_plans')
colSums(is.na(data_filtered2))
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment", NA
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment", "NA")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,24,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
data_filtered3 <- na.omit(data_filtered2, cols='survey_plans')
colSums(is.na(data_filtered3))
numeric_data <- data_filtered %>%
select_if(is.numeric)
# Covariance matrix
heatmap.2(cor(numeric_data),
col = colorRampPalette(c("blue", "white", "red"))(20),
main = "Correlation Heatmap",
key = TRUE,
symkey = FALSE)
View(data_filtered3)
View(data_filtered2)
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment", NA
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment", "NA")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,24,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
# numeric_data <- data_filtered %>%
#   select_if(is.numeric)
#
# # Covariance matrix
# heatmap.2(cor(numeric_data),
#           col = colorRampPalette(c("blue", "white", "red"))(20),
#           main = "Correlation Heatmap",
#           key = TRUE,
#           symkey = FALSE)
View(filtered)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,24,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
unique(data_filtered$survey_city)
unique(data_filtered$survey_state)
unique(data_filtered$survey_company)
unique(data_filtered$survey_state)
state_vals = unique(data_filtered$survey_state)
state_vals
filtered$survey_state <- tolower(filtered$survey_state)
print(state_vals = unique(filtered$survey_state))
filtered$survey_state <- tolower(filtered$survey_state)
print(unique(filtered$survey_state))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state)
print(unique(filtered$survey_state))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb))
print(unique(filtered$survey_state))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[na.omit(filtered$survey_state)]
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment", NA
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment", "NA")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
numeric_data <- data_filtered %>%
select_if(is.numeric)
# Covariance matrix
heatmap.2(cor(numeric_data),
col = colorRampPalette(c("blue", "white", "red"))(20),
main = "Correlation Heatmap",
key = TRUE,
symkey = FALSE)
numeric_data <- data_filtered %>%
select_if(is.numeric)
# # Covariance matrix
# heatmap.2(cor(numeric_data),
#           col = colorRampPalette(c("blue", "white", "red"))(20),
#           main = "Correlation Heatmap",
#           key = TRUE,
#           symkey = FALSE)
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
View(filtered)
View(filtered)
print(unique(filtered$survey_state))
print(unique(filtered$survey_city))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
print(unique(filtered$survey_city))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
print(sort(unique(filtered$survey_city)))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
print(sort(unique(filtered$survey_city)))
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment", NA
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment", "NA")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
print(sort(unique(filtered$survey_city)))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
print(sort(unique(filtered$survey_city)))
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
unique(filtered$survey_city)
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
sort(unique(filtered$survey_city))
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
print(sort(unique(filtered$survey_city)))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
print(sort(unique(filtered$survey_city)))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
sort(unique(filtered$survey_state))
print(sort(unique(filtered$survey_state)))
unique(filtered$survey_state))
unique(filtered$survey_state)
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
sort(unique(filtered$survey_city))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
sort(unique(filtered$survey_city))
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
sort(unique(filtered$survey_city))
filtered$survey_company <- tolower(filtered$survey_company) # to lower case
sort(unique(filtered$survey_company))
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm, gplots, ggplot)
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
options(scipen = 999)
# Removing those who are "seeking continuing education", "continuing education", "not seeking employment"
ValueToRemove = c("seeking continuing education", "continuing education", "not seeking employment")
data_filtered <- data[!(data$survey_plans %in% ValueToRemove), ]
unique(data_filtered$survey_plans)
# Remove the specified columns by their column numbers
data_filtered2 <- data_filtered[, c(2,3,22,23,25,27,28,29,37,38,39,40,41,42)]
head(data_filtered2)
colSums(is.na(data_filtered2))
filtered <- subset(data_filtered2, !is.na(survey_plans))
colSums(is.na(filtered))
filtered$survey_state <- tolower(filtered$survey_state) # to lower case
filtered$survey_state <- gsub("[^a-zA-Z]", "", filtered$survey_state) # remove abbreviations
filtered$survey_state <- match(filtered$survey_state, tolower(state.abb)) # convert to numerical representations
filtered$survey_state <- state.name[(filtered$survey_state)]
print(unique(filtered$survey_state))
filtered$survey_city <- tolower(filtered$survey_city) # to lower case
filtered$survey_city <- gsub("[^a-zA-Z]", "", filtered$survey_city) # remove abbreviations
filtered$survey_city <- gsub("\\s+", "", filtered$survey_city) # remove extra spaces
filtered$survey_city <- gsub(" city$", '' ,  filtered$survey_city) # remove string city on the end
sort(unique(filtered$survey_city))
# to drop : indiana, dontknowyet, na, tbd, various
filtered$survey_city[filtered$survey_city == "cincinatti"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnnati"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == "cincinnatioh"] <- "cincinnati"
filtered$survey_city[filtered$survey_city == 'findlaytentative'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'findley'] <- 'findlay'
filtered$survey_city[filtered$survey_city == 'ftmyers'] <- 'fortmyers'
filtered$survey_city[filtered$survey_city == 'hamiliton'] <- 'hamilton'
filtered$survey_city[filtered$survey_city == 'milwaukwee'] <- 'milwaukee'
filtered$survey_city[filtered$survey_city == 'newyork'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'nyc'] <- 'newyorkcity'
filtered$survey_city[filtered$survey_city == 'philadephia'] <- 'philadelphia'
filtered$survey_city[filtered$survey_city == 'springfieldoh'] <- 'springfield'
filtered$survey_city[filtered$survey_city == 'washinton'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'washingtondc'] <- 'washington'
filtered$survey_city[filtered$survey_city == 'westervillecolumbus'] <- 'westerville'
filtered$survey_city[filtered$survey_city == 'witchita'] <- 'wichita'
sort(unique(filtered$survey_city))
# Drop Rows with the following values : indiana, dontknowyet, na, tbd, various
ValueToRemove = c("indiana", "dontknowyet", "na", "tbd", "various", "NA")
filtered <- filtered[!(filtered$survey_city %in% ValueToRemove), ]
sort(unique(filtered$survey_city))
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.2
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
install.packages("stringdist")
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.2
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
install.packages("stringdist")
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.2
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
clustered_data
install.packages("stringdist")
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.5
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
sort(unique(filtered$survey_city))
install.packages("stringdist")
library(stringdist)
# Load your survey data into a data frame (replace this with your actual data)
survey_data <- filtered
survey_data <- survey_data[complete.cases(survey_data$survey_company), ]
# Create a function to cluster similar company names
cluster_similar_names <- function(data, threshold = 0.2) {
# Calculate the string distances between company names
dist_matrix <- stringdistmatrix(data$survey_company, data$survey_company, method = "jw")
# Create a hierarchical clustering based on string distances
hclust_result <- hclust(as.dist(dist_matrix))
# Cut the tree into clusters based on the threshold
clusters <- cutree(hclust_result, h = threshold)
# Add the cluster IDs to the original data frame
data$survey_company_id <- clusters
return(data)
}
# Set a threshold for clustering (adjust as needed)
threshold <- 0.5
# Cluster similar company names
clustered_data <- cluster_similar_names(survey_data, threshold)
sort(unique(filtered$survey_city))
sort(unique(filtered$survey_company))
clustered_data
data <- filtered
# Create an empty vector to store the matched names
matched_names <- character(0)
# Loop through the company names and find matches for each
for (search_term in data$survey_company) {
fuzzy_matches <- stringdistmatrix(search_term, data$survey_company, method = "jw")
# Adjust the threshold as needed
threshold <- 0.5  # You can adjust this threshold
# Find matches with a similarity threshold
potential_matches <- which(fuzzy_matches <= threshold, arr.ind = TRUE)
# Get the matched company names using row index
matched_names <- c(matched_names, data$survey_company[potential_matches[, "row"]])
}
data <- filtered$survey_company
# Create an empty vector to store the matched names
matched_names <- character(0)
# Loop through the company names and find matches for each
for (search_term in data$survey_company) {
fuzzy_matches <- stringdistmatrix(search_term, data$survey_company, method = "jw")
# Adjust the threshold as needed
threshold <- 0.5  # You can adjust this threshold
# Find matches with a similarity threshold
potential_matches <- which(fuzzy_matches <= threshold, arr.ind = TRUE)
# Get the matched company names using row index
matched_names <- c(matched_names, data$survey_company[potential_matches[, "row"]])
}
data <- filtered
# Create an empty vector to store the matched names
matched_names <- character(0)
# Loop through the company names and find matches for each
for (search_term in data$survey_company) {
fuzzy_matches <- stringdistmatrix(search_term, data$survey_company, method = "jw")
# Adjust the threshold as needed
threshold <- 0.5  # You can adjust this threshold
# Find matches with a similarity threshold
potential_matches <- which(fuzzy_matches <= threshold, arr.ind = TRUE)
# Get the matched company names using row index
matched_names <- c(matched_names, data$survey_company[potential_matches[, "row"]])
}
# Add the matched names to the original data frame
data$matched_names <- matched_names
